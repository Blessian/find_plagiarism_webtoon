{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyO6UqoYW3SnW2Hz37jUnFj8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"24b695531f8f47a6ba9d2b6cd36eeba1":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_4fa27d56865b4a26b66888efdaf2b6f1","IPY_MODEL_eb6f093e3907483eab01d9dd890aaa95"],"layout":"IPY_MODEL_1e672511eed943eca4fc09c1c31c1ab4"}},"4fa27d56865b4a26b66888efdaf2b6f1":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c025c1ed8e5243258d422e233ddacdfc","placeholder":"​","style":"IPY_MODEL_834527582fcc43c9b6698bf464e82a67","value":"0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"}},"eb6f093e3907483eab01d9dd890aaa95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2b3fd94eb1f48cdba9d600ef4f87286","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53ff2f819b81472b8dc588ff7d8dbfbf","value":1}},"1e672511eed943eca4fc09c1c31c1ab4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c025c1ed8e5243258d422e233ddacdfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"834527582fcc43c9b6698bf464e82a67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2b3fd94eb1f48cdba9d600ef4f87286":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53ff2f819b81472b8dc588ff7d8dbfbf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZX1NFIAAhiry","executionInfo":{"status":"ok","timestamp":1688586637987,"user_tz":-540,"elapsed":14134,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"8efe5b15-d7ac-4b7c-c86f-5e05581c1eb3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["~from google.colab import drive\n","drive.mount('/content/drive')\n","\n","default_path = '/content/drive/My Drive'"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/메타버스 아카데미/본과정/Python/data/dataset\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GOfLpk11hunR","executionInfo":{"status":"ok","timestamp":1688587115787,"user_tz":-540,"elapsed":271,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"df2a0448-2807-4785-b7c6-b059c5d05902"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/메타버스 아카데미/본과정/Python/data/dataset\n","\u001b[0m\u001b[01;34m0\u001b[0m/     \u001b[01;34m1\u001b[0m/     \u001b[01;34m2\u001b[0m/     \u001b[01;34m3\u001b[0m/     \u001b[01;34m4\u001b[0m/     \u001b[01;34m5\u001b[0m/     \u001b[01;34mdataset\u001b[0m/\n","0.csv  1.csv  2.csv  3.csv  4.csv  5.csv  \u001b[01;34mwandb\u001b[0m/\n"]}]},{"cell_type":"code","source":["!pip install wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBrafWwdhylt","executionInfo":{"status":"ok","timestamp":1688586649655,"user_tz":-540,"elapsed":9237,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"2f332ed9-029f-468d-c1c4-b033714b6855"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.15.5-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n","Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-1.27.0-py2.py3-none-any.whl (211 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n","Collecting pathtools (from wandb)\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=27d58bf9f6296789c7b74d0764642864459ba510b528664f7638b5727e7cc3ae\n","  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n","Successfully built pathtools\n","Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n","Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.27.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.5\n"]}]},{"cell_type":"code","source":["!pip install timm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Du6MGWZHiBjk","executionInfo":{"status":"ok","timestamp":1688586656300,"user_tz":-540,"elapsed":6648,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"2246445d-598f-477f-a0dc-5683ecbf4092"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting timm\n","  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/2.2 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.1+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.2+cu118)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n","Collecting huggingface-hub (from timm)\n","  Downloading huggingface_hub-0.16.2-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.5/268.5 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors (from timm)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","Installing collected packages: safetensors, huggingface-hub, timm\n","Successfully installed huggingface-hub-0.16.2 safetensors-0.3.1 timm-0.9.2\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import copy\n","import uuid\n","\n","import torch\n","import torch.nn as nn\n","from torchvision import models, transforms\n","\n","import cv2\n","import numpy as np\n","\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","\n","\n","def set_augmentations(task):\n","    if task == 'train':\n","        temp_transforms = transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.RandomHorizontalFlip(p=0.5),\n","        transforms.RandomRotation(90),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","        ])\n","\n","    elif task in ['valid', 'test']:\n","        temp_transforms = transforms.Compose([\n","        transforms.Resize((224,224)),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n","])\n","    else:\n","        print('#' * 30, 'Please confirm your task name', '#' * 30)\n","\n","    return temp_transforms\n","\n","def visualize_augmentations(dataset, index=0, samples=20, columns=5):\n","    dataset = copy.deepcopy(dataset)\n","    dataset.transforms = A.Compose([transform for transform in dataset.transforms if not isinstance(transform, (A.Normalize, ToTensorV2))])\n","\n","    rows = samples // columns\n","    _, axis = plt.subplots(nrows=rows, ncols=columns, figsize=(12, 6))\n","\n","    for i in range(samples):\n","        image, _ = dataset[index]\n","        axis.ravel()[i].imshow(image)\n","        # image = image.permute(1, 2, 0)\n","        # print('#' * 50, image.shape)\n","        # https://stackoverflow.com/questions/50963283/imshow-doesnt-need-convert-from-bgr-to-rgb\n","        # https://github.com/philipperemy/keract/issues/46\n","        axis.ravel()[i].set_axis_off()\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","def train(train_loader, valid_loader, epochs, model, device, criterion, optimizer, scheduler):\n","    import wandb\n","\n","    wandb.login()\n","    wandb.init(project=f\"{model._get_name()}\")\n","    wandb.config = {\"learning_rate\": optimizer.param_groups[0]['lr'],\n","                    \"epochs\": epochs,\n","                    \"batch_size\": train_loader.batch_size,\n","                    \"classes\": 6,}\n","    wandb.watch(model)\n","\n","    model_name = model._get_name()\n","    best_valid_accuracy = 0.0\n","\n","    train_steps = len(train_loader)\n","\n","    save_path = os.path.join('./', '{}_best.pt'.format(model_name))\n","\n","    accuracy_df = pd.DataFrame(index=list(range(epochs)), columns=['Epoch',\n","                                                                      'Model',\n","                                                                      'Optimizer',\n","                                                                      'Batch size',\n","                                                                      'Scheduler',\n","                                                                      'Learning Rate',\n","                                                                      'Train Loss',\n","                                                                      'Train Accuracy',\n","                                                                      'Valid Loss',\n","                                                                      'Valid Accuracy'])\n","\n","    if os.path.exists(save_path):\n","        best_valid_accuracy = max(pd.read_csv('./{}_accuracy.csv'.format(model_name))['Accuracy'].tolist())\n","\n","    for epoch in range(1, epochs + 1):\n","        train_running_loss = 0.0\n","        train_corrects = 0\n","        train_length = 0\n","\n","        model.train()\n","        train_bar = tqdm(train_loader, file=sys.stdout, colour='green')\n","\n","        for image_batch, label_batch in train_bar:\n","            image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n","\n","            outputs = model(image_batch)\n","            train_loss = criterion(outputs, label_batch)\n","\n","            optimizer.zero_grad()\n","            train_corrects += (torch.argmax(outputs, dim=1) == label_batch).sum().item()\n","            train_loss.backward()\n","            optimizer.step()\n","            train_running_loss += train_loss.item()\n","            train_length += image_batch.size(0)\n","\n","            train_bar.desc = 'Train Epoch: [{:3d} / {:3d}]   Loss: {:.3f}'.format(\n","                epoch, epochs, train_loss.data\n","            )\n","\n","        train_accuracy = train_corrects / train_length\n","        train_average_loss = train_running_loss / train_steps\n","\n","        valid_accuracy, valid_average_loss = validate(valid_loader, model, device, criterion, epoch)\n","\n","        accuracy_df.loc[epoch, 'Epoch'] = epoch\n","        accuracy_df.loc[epoch, 'Model'] = model_name\n","        accuracy_df.loc[epoch, 'Optimizer'] = type(optimizer).__name__\n","        accuracy_df.loc[epoch, 'Batch size'] = train_loader.batch_size\n","        accuracy_df.loc[epoch, 'Learning Rate'] = optimizer.param_groups[0]['lr']\n","        accuracy_df.loc[epoch, 'Train Loss'] = round(train_average_loss, 3)\n","        accuracy_df.loc[epoch, 'Train Accuracy'] = round(train_accuracy, 3)\n","        accuracy_df.loc[epoch, 'Valid Loss'] = round(valid_average_loss, 3)\n","        accuracy_df.loc[epoch, 'Valid Accuracy'] = round(valid_accuracy, 3)\n","\n","        wandb.log({\n","            \"Epoch\": epoch,\n","            \"Learning Rate\": optimizer.param_groups[0]['lr'],\n","            \"Train Loss\": round(train_average_loss, 3),\n","            \"Train Accuracy\": round(train_accuracy, 3),\n","            \"Valid Loss\": round(valid_average_loss, 3),\n","            \"Valid Accuracy\": round(valid_accuracy, 3),\n","        })\n","\n","        if scheduler is not None:\n","            accuracy_df.loc[epoch, 'Scheduler'] = type(scheduler).__name__\n","            scheduler.step()\n","\n","        print('Epoch: [{:3d} / {:3d}]   Train Loss: {:.3f}   Train Accuracy: {:.3f}   Valid Loss: {:.3f}   Valid Accuracy: {:.3f}'.format(\n","            epoch, epochs, train_average_loss, train_accuracy, valid_average_loss, valid_accuracy\n","        ))\n","\n","        if valid_accuracy > best_valid_accuracy:\n","            best_valid_accuracy = valid_accuracy\n","            torch.save(model.state_dict(), save_path)\n","\n","        if epoch == epochs:\n","            accuracy_df.to_csv('./{}_accuracy.csv'.format(model_name), index=False)\n","\n","        if epoch % 10 == 0:\n","            torch.save(model.state_dict(), './{}_{}_epoch.pt'.format(model_name, epoch))\n","\n","\n","def validate(valid_loader, model, device, criterion, epoch):\n","    valid_steps = len(valid_loader)\n","    valid_running_loss = 0.0\n","    valid_corrects = 0\n","    valid_length = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","\n","        valid_bar = tqdm(valid_loader, file=sys.stdout, colour='red')\n","\n","        for valid_batch in valid_bar:\n","            image_batch, label_batch = valid_batch\n","            image_batch, label_batch = image_batch.to(device), label_batch.to(device)\n","\n","            outputs = model(image_batch)\n","            valid_loss = criterion(outputs, label_batch)\n","            valid_corrects += (torch.argmax(outputs, dim=1) == label_batch).sum().item()\n","            valid_running_loss += valid_loss.item()\n","            valid_length += image_batch.size(0)\n","\n","            collect_failed_predictions(epoch, image_batch, label_batch, (torch.argmax(outputs, dim=1) == label_batch))\n","\n","    valid_accuracy = valid_corrects / valid_length\n","    valid_average_loss = valid_running_loss / valid_steps\n","\n","    return valid_accuracy, valid_average_loss\n","\n","\n","def collect_failed_predictions(epoch, image_batch, label_batch, corrects_tensor):\n","    dir_path = os.path.join('./', 'incorrect', str(epoch))\n","    os.makedirs(dir_path, exist_ok=True)\n","\n","    incorrect_list = corrects_tensor.tolist()\n","    label_list = label_batch.tolist()\n","\n","    for index, correct in enumerate(incorrect_list):\n","        if not correct:\n","            uuid_path = '{}_{}.png'.format(label_list[index], str(uuid.uuid1()))\n","            dest_path = os.path.join(dir_path, uuid_path)\n","            image_tensor = image_batch[index]\n","            image = get_image_from_tensor(image_tensor)\n","\n","            cv2.imwrite(dest_path, image)\n","\n","\n","def denormalize(normalized_image):\n","    # # In case: normalize by /255.\n","    # image = image * 255.0\n","\n","    IMAGENET_MEAN, IMAGENET_STD = np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225])\n","    image = np.clip(255.0 * (normalized_image * IMAGENET_STD + IMAGENET_MEAN), 0, 255)\n","\n","    return image\n","\n","\n","def get_image_from_tensor(image_tensor):\n","    # Tensor formed image [C, H, W]\n","    # tensor -> numpy\n","    temp_image = image_tensor.detach().cpu().numpy()\n","    # [C,H,W] -> [H,W,C]\n","    temp_image = np.transpose(temp_image, (1, 2, 0))\n","    # Denormalize\n","    temp_image = denormalize(temp_image)\n","    # np.float32 -> np.uint8\n","    image = temp_image.astype(np.uint8)\n","    # # BGR to RGB\n","    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","    return image\n","\n","\n","def test(test_loader, device, label_volume):\n","    model = models.mobilenet_v2(pretrained=True)\n","    model.classifier[1].out_features = label_volume\n","    model.load_state_dict(torch.load(f'./{model._get_name()}/{model._get_name()}_best.pt'.format(), map_location=device))\n","    model.to(device)\n","\n","    correct = 0\n","    total = 0\n","\n","    model.eval()\n","    with torch.no_grad():\n","        for i, (image, label) in enumerate(test_loader):\n","            images, labels = image.to(device), label.to(device)\n","\n","            output = model(images)\n","            _, argmax = torch.max(output, dim=1)\n","            total += images.size(0)\n","            correct += (labels == argmax).sum().item()\n","\n","        accuracy = accuracy_function(correct, total)\n","        print('Accuracy: ', accuracy)\n","\n","\n","def accuracy_function(correct, total):\n","    accuracy = correct / total * 100\n","    return accuracy\n","\n","\n","# import os\n","# from custom_dataset import CustomDataset\n","# data_path = os.path.join('../', 'dataset')\n","# transforms = set_augmentations('train')\n","# train_dataset = CustomDataset(data_path, transforms=transforms, task='train')\n","# visualize_augmentations(train_dataset)"],"metadata":{"id":"O24ene7XiFSS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","\n","from torchvision import models, datasets\n","\n","from timm.loss import LabelSmoothingCrossEntropy\n","\n","# Set Paramerts\n","epoch_num = 50\n","batch_size = 32\n","label_volume = 6\n","dataset_path = os.path.join('../', 'dataset')\n","step_size = 9                                 # resnet50\n","gamma = 0.1                                   # resnet50\n","learning_rate = 2e-4                          # resnet50-AdamW\n","# step_size = 30                                # resnet18\n","# learning_rate = 1e-3                          # resnet18-SGD\n","# learning_rate = 1e-2                          # resnet18-AdamW\n","\n","\n","# Set Device\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","# Set Augmentations\n","train_transforms = set_augmentations('train')\n","valid_transforms = set_augmentations('valid')\n","\n","# Load Dataset\n","train_dataset = datasets.ImageFolder(\"./dataset/train\", transform=train_transforms)\n","valid_dataset = datasets.ImageFolder(\"./dataset/valid\", transform=valid_transforms)\n","\n","# Set DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n","# print(len(train_dataset), '##', len(train_loader))\n","# exit()\n","\n","# Call Model\n","model = models.mobilenet_v2(pretrained=True)\n","model.classifier[1].out_features = label_volume\n","model.to(device)\n","# print(model._get_name())\n","# exit()\n","\n","# Set Criterion\n","criterion = LabelSmoothingCrossEntropy()\n","\n","# Set Optimizer\n","optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n","# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","\n","# Set Scheduler\n","# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n","\n","\n","if __name__ == '__main__':\n","    # Train and validate\n","    train(train_loader, valid_loader, epoch_num, model, device, criterion, optimizer, scheduler)\n","\n","    # Save last.pt\n","    torch.save(model.state_dict(), './{}_last.pt'.format(model._get_name()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["24b695531f8f47a6ba9d2b6cd36eeba1","4fa27d56865b4a26b66888efdaf2b6f1","eb6f093e3907483eab01d9dd890aaa95","1e672511eed943eca4fc09c1c31c1ab4","c025c1ed8e5243258d422e233ddacdfc","834527582fcc43c9b6698bf464e82a67","f2b3fd94eb1f48cdba9d600ef4f87286","53ff2f819b81472b8dc588ff7d8dbfbf"]},"id":"psMgQntEiSPS","executionInfo":{"status":"ok","timestamp":1688587827830,"user_tz":-540,"elapsed":173548,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"deef2703-02af-49a8-cfda-4330aa7bb268"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Finishing last run (ID:q8ygbb06) before initializing another..."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24b695531f8f47a6ba9d2b6cd36eeba1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">stellar-darkness-1</strong> at: <a href='https://wandb.ai/blessian/Inception3/runs/q8ygbb06' target=\"_blank\">https://wandb.ai/blessian/Inception3/runs/q8ygbb06</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230705_200432-q8ygbb06/logs</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Successfully finished last run (ID:q8ygbb06). Initializing new run:<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.5"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/메타버스 아카데미/본과정/Python/data/dataset/wandb/run-20230705_200734-6iwvxl8w</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/blessian/MobileNetV2/runs/6iwvxl8w' target=\"_blank\">radiant-capybara-8</a></strong> to <a href='https://wandb.ai/blessian/MobileNetV2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/blessian/MobileNetV2' target=\"_blank\">https://wandb.ai/blessian/MobileNetV2</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/blessian/MobileNetV2/runs/6iwvxl8w' target=\"_blank\">https://wandb.ai/blessian/MobileNetV2/runs/6iwvxl8w</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\r  0%|\u001b[32m          \u001b[0m| 0/10 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [  1 /  50]   Loss: 3.178: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:03<00:00,  3.18it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  1.96it/s]\n","Epoch: [  1 /  50]   Train Loss: 7.189   Train Accuracy: 0.118   Valid Loss: 7.095   Valid Accuracy: 0.103\n","Train Epoch: [  2 /  50]   Loss: 2.103: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.76it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.11it/s]\n","Epoch: [  2 /  50]   Train Loss: 2.545   Train Accuracy: 0.742   Valid Loss: 3.989   Valid Accuracy: 0.500\n","Train Epoch: [  3 /  50]   Loss: 2.315: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.81it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.30it/s]\n","Epoch: [  3 /  50]   Train Loss: 2.028   Train Accuracy: 0.840   Valid Loss: 2.614   Valid Accuracy: 0.667\n","Train Epoch: [  4 /  50]   Loss: 1.746: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.95it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.17it/s]\n","Epoch: [  4 /  50]   Train Loss: 1.697   Train Accuracy: 0.925   Valid Loss: 3.094   Valid Accuracy: 0.564\n","Train Epoch: [  5 /  50]   Loss: 1.350: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:03<00:00,  3.19it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.22it/s]\n","Epoch: [  5 /  50]   Train Loss: 1.489   Train Accuracy: 0.948   Valid Loss: 2.294   Valid Accuracy: 0.615\n","Train Epoch: [  6 /  50]   Loss: 1.523: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.11it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.41it/s]\n","Epoch: [  6 /  50]   Train Loss: 1.441   Train Accuracy: 0.951   Valid Loss: 2.085   Valid Accuracy: 0.679\n","Train Epoch: [  7 /  50]   Loss: 1.468: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.69it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.57it/s]\n","Epoch: [  7 /  50]   Train Loss: 1.390   Train Accuracy: 0.971   Valid Loss: 2.132   Valid Accuracy: 0.769\n","Train Epoch: [  8 /  50]   Loss: 1.393: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:01<00:00,  5.03it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.62it/s]\n","Epoch: [  8 /  50]   Train Loss: 1.347   Train Accuracy: 0.984   Valid Loss: 2.410   Valid Accuracy: 0.769\n","Train Epoch: [  9 /  50]   Loss: 1.276: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.67it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.38it/s]\n","Epoch: [  9 /  50]   Train Loss: 1.323   Train Accuracy: 0.971   Valid Loss: 1.867   Valid Accuracy: 0.859\n","Train Epoch: [ 10 /  50]   Loss: 1.274: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:04<00:00,  2.35it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.48it/s]\n","Epoch: [ 10 /  50]   Train Loss: 1.282   Train Accuracy: 0.990   Valid Loss: 1.759   Valid Accuracy: 0.859\n","Train Epoch: [ 11 /  50]   Loss: 1.286: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.75it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.11it/s]\n","Epoch: [ 11 /  50]   Train Loss: 1.276   Train Accuracy: 0.997   Valid Loss: 1.701   Valid Accuracy: 0.859\n","Train Epoch: [ 12 /  50]   Loss: 1.447: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.80it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.69it/s]\n","Epoch: [ 12 /  50]   Train Loss: 1.302   Train Accuracy: 0.980   Valid Loss: 1.678   Valid Accuracy: 0.846\n","Train Epoch: [ 13 /  50]   Loss: 1.322: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.80it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.71it/s]\n","Epoch: [ 13 /  50]   Train Loss: 1.275   Train Accuracy: 0.990   Valid Loss: 1.678   Valid Accuracy: 0.846\n","Train Epoch: [ 14 /  50]   Loss: 1.284: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:03<00:00,  3.16it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.75it/s]\n","Epoch: [ 14 /  50]   Train Loss: 1.271   Train Accuracy: 0.990   Valid Loss: 1.662   Valid Accuracy: 0.885\n","Train Epoch: [ 15 /  50]   Loss: 1.357: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.84it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.05it/s]\n","Epoch: [ 15 /  50]   Train Loss: 1.254   Train Accuracy: 0.990   Valid Loss: 1.661   Valid Accuracy: 0.885\n","Train Epoch: [ 16 /  50]   Loss: 1.231: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.78it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.63it/s]\n","Epoch: [ 16 /  50]   Train Loss: 1.262   Train Accuracy: 0.984   Valid Loss: 1.695   Valid Accuracy: 0.872\n","Train Epoch: [ 17 /  50]   Loss: 1.291: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.92it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.97it/s]\n","Epoch: [ 17 /  50]   Train Loss: 1.259   Train Accuracy: 0.990   Valid Loss: 1.732   Valid Accuracy: 0.872\n","Train Epoch: [ 18 /  50]   Loss: 1.203: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.14it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.54it/s]\n","Epoch: [ 18 /  50]   Train Loss: 1.246   Train Accuracy: 0.993   Valid Loss: 1.755   Valid Accuracy: 0.859\n","Train Epoch: [ 19 /  50]   Loss: 1.289: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:03<00:00,  3.17it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.76it/s]\n","Epoch: [ 19 /  50]   Train Loss: 1.237   Train Accuracy: 0.997   Valid Loss: 1.741   Valid Accuracy: 0.859\n","Train Epoch: [ 20 /  50]   Loss: 1.305: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.76it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.80it/s]\n","Epoch: [ 20 /  50]   Train Loss: 1.241   Train Accuracy: 0.987   Valid Loss: 1.745   Valid Accuracy: 0.821\n","Train Epoch: [ 21 /  50]   Loss: 1.233: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.85it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.95it/s]\n","Epoch: [ 21 /  50]   Train Loss: 1.228   Train Accuracy: 0.993   Valid Loss: 1.737   Valid Accuracy: 0.859\n","Train Epoch: [ 22 /  50]   Loss: 1.224: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.75it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.05it/s]\n","Epoch: [ 22 /  50]   Train Loss: 1.246   Train Accuracy: 0.990   Valid Loss: 1.707   Valid Accuracy: 0.859\n","Train Epoch: [ 23 /  50]   Loss: 1.215: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  3.54it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.45it/s]\n","Epoch: [ 23 /  50]   Train Loss: 1.230   Train Accuracy: 0.997   Valid Loss: 1.689   Valid Accuracy: 0.872\n","Train Epoch: [ 24 /  50]   Loss: 1.276: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  3.73it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.87it/s]\n","Epoch: [ 24 /  50]   Train Loss: 1.243   Train Accuracy: 0.993   Valid Loss: 1.711   Valid Accuracy: 0.859\n","Train Epoch: [ 25 /  50]   Loss: 1.311: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.80it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.00it/s]\n","Epoch: [ 25 /  50]   Train Loss: 1.245   Train Accuracy: 0.993   Valid Loss: 1.696   Valid Accuracy: 0.872\n","Train Epoch: [ 26 /  50]   Loss: 1.322: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.83it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.07it/s]\n","Epoch: [ 26 /  50]   Train Loss: 1.256   Train Accuracy: 0.990   Valid Loss: 1.692   Valid Accuracy: 0.872\n","Train Epoch: [ 27 /  50]   Loss: 1.234: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.78it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.75it/s]\n","Epoch: [ 27 /  50]   Train Loss: 1.244   Train Accuracy: 0.984   Valid Loss: 1.708   Valid Accuracy: 0.859\n","Train Epoch: [ 28 /  50]   Loss: 1.258: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:03<00:00,  3.23it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.64it/s]\n","Epoch: [ 28 /  50]   Train Loss: 1.245   Train Accuracy: 0.987   Valid Loss: 1.714   Valid Accuracy: 0.833\n","Train Epoch: [ 29 /  50]   Loss: 1.347: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.19it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.08it/s]\n","Epoch: [ 29 /  50]   Train Loss: 1.247   Train Accuracy: 0.984   Valid Loss: 1.723   Valid Accuracy: 0.859\n","Train Epoch: [ 30 /  50]   Loss: 1.314: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.81it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.69it/s]\n","Epoch: [ 30 /  50]   Train Loss: 1.268   Train Accuracy: 0.980   Valid Loss: 1.714   Valid Accuracy: 0.846\n","Train Epoch: [ 31 /  50]   Loss: 1.215: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.67it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.91it/s]\n","Epoch: [ 31 /  50]   Train Loss: 1.247   Train Accuracy: 0.990   Valid Loss: 1.700   Valid Accuracy: 0.859\n","Train Epoch: [ 32 /  50]   Loss: 1.208: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  3.78it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.02it/s]\n","Epoch: [ 32 /  50]   Train Loss: 1.236   Train Accuracy: 0.987   Valid Loss: 1.704   Valid Accuracy: 0.833\n","Train Epoch: [ 33 /  50]   Loss: 1.222: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:03<00:00,  2.90it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.17it/s]\n","Epoch: [ 33 /  50]   Train Loss: 1.240   Train Accuracy: 0.993   Valid Loss: 1.668   Valid Accuracy: 0.872\n","Train Epoch: [ 34 /  50]   Loss: 1.263: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  3.80it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.87it/s]\n","Epoch: [ 34 /  50]   Train Loss: 1.233   Train Accuracy: 0.997   Valid Loss: 1.713   Valid Accuracy: 0.872\n","Train Epoch: [ 35 /  50]   Loss: 1.198: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.84it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.21it/s]\n","Epoch: [ 35 /  50]   Train Loss: 1.265   Train Accuracy: 0.990   Valid Loss: 1.717   Valid Accuracy: 0.885\n","Train Epoch: [ 36 /  50]   Loss: 1.358: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.98it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.08it/s]\n","Epoch: [ 36 /  50]   Train Loss: 1.254   Train Accuracy: 0.980   Valid Loss: 1.687   Valid Accuracy: 0.872\n","Train Epoch: [ 37 /  50]   Loss: 1.234: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.83it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.41it/s]\n","Epoch: [ 37 /  50]   Train Loss: 1.246   Train Accuracy: 0.993   Valid Loss: 1.687   Valid Accuracy: 0.872\n","Train Epoch: [ 38 /  50]   Loss: 1.231: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:03<00:00,  3.24it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.71it/s]\n","Epoch: [ 38 /  50]   Train Loss: 1.247   Train Accuracy: 0.993   Valid Loss: 1.687   Valid Accuracy: 0.872\n","Train Epoch: [ 39 /  50]   Loss: 1.216: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.31it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.77it/s]\n","Epoch: [ 39 /  50]   Train Loss: 1.234   Train Accuracy: 0.990   Valid Loss: 1.684   Valid Accuracy: 0.872\n","Train Epoch: [ 40 /  50]   Loss: 1.348: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.90it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.17it/s]\n","Epoch: [ 40 /  50]   Train Loss: 1.272   Train Accuracy: 0.977   Valid Loss: 1.682   Valid Accuracy: 0.872\n","Train Epoch: [ 41 /  50]   Loss: 1.216: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.91it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.12it/s]\n","Epoch: [ 41 /  50]   Train Loss: 1.243   Train Accuracy: 0.987   Valid Loss: 1.700   Valid Accuracy: 0.872\n","Train Epoch: [ 42 /  50]   Loss: 1.213: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.90it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.50it/s]\n","Epoch: [ 42 /  50]   Train Loss: 1.250   Train Accuracy: 0.997   Valid Loss: 1.716   Valid Accuracy: 0.859\n","Train Epoch: [ 43 /  50]   Loss: 1.570: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:03<00:00,  3.32it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.82it/s]\n","Epoch: [ 43 /  50]   Train Loss: 1.265   Train Accuracy: 0.993   Valid Loss: 1.723   Valid Accuracy: 0.846\n","Train Epoch: [ 44 /  50]   Loss: 1.209: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.88it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  4.01it/s]\n","Epoch: [ 44 /  50]   Train Loss: 1.243   Train Accuracy: 0.987   Valid Loss: 1.712   Valid Accuracy: 0.859\n","Train Epoch: [ 45 /  50]   Loss: 1.292: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.91it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.89it/s]\n","Epoch: [ 45 /  50]   Train Loss: 1.238   Train Accuracy: 0.990   Valid Loss: 1.712   Valid Accuracy: 0.859\n","Train Epoch: [ 46 /  50]   Loss: 1.331: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.83it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.81it/s]\n","Epoch: [ 46 /  50]   Train Loss: 1.240   Train Accuracy: 0.990   Valid Loss: 1.725   Valid Accuracy: 0.859\n","Train Epoch: [ 47 /  50]   Loss: 1.189: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.51it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:01<00:00,  2.45it/s]\n","Epoch: [ 47 /  50]   Train Loss: 1.236   Train Accuracy: 0.990   Valid Loss: 1.701   Valid Accuracy: 0.859\n","Train Epoch: [ 48 /  50]   Loss: 1.240: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  3.37it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.63it/s]\n","Epoch: [ 48 /  50]   Train Loss: 1.250   Train Accuracy: 0.987   Valid Loss: 1.688   Valid Accuracy: 0.859\n","Train Epoch: [ 49 /  50]   Loss: 1.254: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  4.96it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.93it/s]\n","Epoch: [ 49 /  50]   Train Loss: 1.237   Train Accuracy: 0.993   Valid Loss: 1.693   Valid Accuracy: 0.872\n","Train Epoch: [ 50 /  50]   Loss: 1.435: 100%|\u001b[32m██████████\u001b[0m| 10/10 [00:02<00:00,  5.00it/s]\n","100%|\u001b[31m██████████\u001b[0m| 3/3 [00:00<00:00,  3.87it/s]\n","Epoch: [ 50 /  50]   Train Loss: 1.305   Train Accuracy: 0.977   Valid Loss: 1.702   Valid Accuracy: 0.846\n"]}]},{"cell_type":"code","source":["test_dataset = datasets.ImageFolder(\"./dataset/test\", transform=valid_transforms)\n","test_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n","\n","test(test_loader, device, label_volume)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UsHzgHB4qeLQ","executionInfo":{"status":"ok","timestamp":1688589440581,"user_tz":-540,"elapsed":1706,"user":{"displayName":"Blessian White","userId":"18309571065164793243"}},"outputId":"9fe13b78-4ef2-4777-f7d6-7b5425bd3c81"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy:  88.46153846153845\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"h7sO8EEhA0Jj"},"execution_count":null,"outputs":[]}]}